{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset : \n",
      "\n",
      "[[8.450e+03 7.000e+00 5.000e+00 ... 0.000e+00 5.480e+02 1.000e+00]\n",
      " [9.600e+03 6.000e+00 8.000e+00 ... 1.000e+00 4.600e+02 1.000e+00]\n",
      " [1.125e+04 7.000e+00 5.000e+00 ... 1.000e+00 6.080e+02 1.000e+00]\n",
      " ...\n",
      " [9.042e+03 7.000e+00 9.000e+00 ... 2.000e+00 2.520e+02 1.000e+00]\n",
      " [9.717e+03 5.000e+00 6.000e+00 ... 0.000e+00 2.400e+02 0.000e+00]\n",
      " [9.937e+03 5.000e+00 6.000e+00 ... 0.000e+00 2.760e+02 0.000e+00]]\n",
      "\n",
      "Dimensions of dataset : (1460, 11)\n"
     ]
    }
   ],
   "source": [
    "data_orig = np.genfromtxt('data/housepricedata.csv',delimiter=',',skip_header=1)\n",
    "print(\"Dataset : \\n\\n\"+ str(data_orig))\n",
    "print(\"\\nDimensions of dataset : \"+str(data_orig.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Y   :[1. 1. 1. ... 1. 0. 0.]\n",
      "Shape of Y : (1460,)\n"
     ]
    }
   ],
   "source": [
    "#Extacting Y\n",
    "y_orig = data_orig[:,-1]\n",
    "print(\"Output Y   :\"+str(y_orig))\n",
    "print(\"Shape of Y : \"+str(y_orig.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Y: (1, 1460)\n",
      "49.86301369863014\n"
     ]
    }
   ],
   "source": [
    "#Removing Rank 1 array\n",
    "Y = np.reshape(y_orig,(y_orig.shape[0],1)).T    \n",
    "print(\"Shape of Y: \"+ str(Y.shape))\n",
    "print((np.sum(Y)/1460)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting vectorized input feature X (transposed)\n",
    "X = data_orig[:,0:-1].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1460)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of Training set X : (10, 1168)\n",
      "Shape of Training set Y : (1, 1168)\n",
      "\n",
      "Shape of Test set   X   : (10, 292)\n",
      "Shape of Test set Y     : (1, 292)\n"
     ]
    }
   ],
   "source": [
    "#Splitting into Train, Test sets ( with a fixed seed )\n",
    "train_split_percent = 80\n",
    "test_split_percent = 20\n",
    "\n",
    "train_X , test_X = X[:, : int( (train_split_percent/100)*X.shape[1])] , X[:,int( (train_split_percent/100)*X.shape[1]) : ]\n",
    "train_Y , test_Y = Y[:, : int( (train_split_percent/100)*X.shape[1])] , Y[:,int( (train_split_percent/100)*X.shape[1]) : ]\n",
    "print(\"\\nShape of Training set X : \"+str(train_X.shape))\n",
    "print(\"Shape of Training set Y : \"+str(train_Y.shape))\n",
    "print(\"\\nShape of Test set   X   : \"+str(test_X.shape))\n",
    "print(\"Shape of Test set Y     : \"+str(test_Y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of training examples : 1168\n",
      "No of test example      : 292\n",
      "50.0\n"
     ]
    }
   ],
   "source": [
    "m_train = train_X.shape[1]\n",
    "m_test  = test_X.shape[1]\n",
    "print(\"No of training examples : \"+str(m_train))\n",
    "print(\"No of test example      : \"+str(m_test))\n",
    "print((np.sum(1-test_Y)/292)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(x):\n",
    "    x_mean = np.mean(x,axis=1, keepdims=True)\n",
    "    x_std = np.std(x, axis=1, keepdims=True)+0.0000001\n",
    "\n",
    "    X = (x - x_mean)/x_std   #Python Broadcasting\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = standardize(train_X)\n",
    "test_X  = standardize(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    sigz= 1/(1+np.exp(-Z))\n",
    "    sigz[sigz==1] = 0.99999999999\n",
    "    sigz[sigz==0] = 0.000000000001\n",
    "    return sigz        \n",
    "\n",
    "def relu(Z):\n",
    "    return np.maximum(0,Z)\n",
    "\n",
    "def sigmoid_backward(dA, Z):\n",
    "    sig = sigmoid(Z)\n",
    "    return dA * sig * (1 - sig)\n",
    "\n",
    "def relu_backward(dA, Z):\n",
    "    dZ = np.array(dA, copy = True)\n",
    "    dZ[Z <= 0] = 0;\n",
    "    return dZ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(n_x, n_h, n_y):\n",
    "    \n",
    "    W1 = np.random.randn(n_h,n_x)*0.1\n",
    "    b1 = np.zeros((n_h,1))\n",
    "    W2 = np.random.randn(n_y,n_h)*0.1\n",
    "    b2 = np.zeros((n_y,1))\n",
    "    \n",
    "    p = {\"W1\": W1,\"b1\": b1,   \"W2\": W2, \"b2\": b2}\n",
    "    \n",
    "    return p "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters_deep(layer_dims):\n",
    "    parameters = {}\n",
    "    L = len(layer_dims)            \n",
    "\n",
    "    for l in range(1, L):\n",
    "        parameters['W' + str(l)] = np.random.randn(layer_dims[l],layer_dims[l-1])*(2/layer_dims[l-1])**0.5\n",
    "        parameters['b' + str(l)] = np.zeros((layer_dims[l],1))\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(A, W, b):\n",
    "   \n",
    "    Z = np.dot(W,A)+b\n",
    "    #Z = standardize(Z) Batch-Normalize with u,var=1\n",
    "    cache = (A, W, b)\n",
    "    \n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_forward(A_prev, W, b, activation,layer):\n",
    "    \n",
    "    \n",
    "    if activation == \"sigmoid\":\n",
    "        Z, linear_cache = linear_forward(A_prev,W,b)\n",
    "        A, activation_cache = sigmoid(Z), sigmoid(Z)\n",
    "    \n",
    "    elif activation == \"relu\":\n",
    "        Z, linear_cache = linear_forward(A_prev,W,b)\n",
    "        A, activation_cache = relu(Z), relu(Z)\n",
    "        dropout_cache = A\n",
    "        D = np.random.rand(A.shape[0],A.shape[1]) \n",
    "        if layer==1:\n",
    "            D[:,:]=1\n",
    "        else:\n",
    "            D = (D < keep_prob).astype(int)                                         \n",
    "            A = A*D                                         \n",
    "            A = A/keep_prob \n",
    "        global Dcache \n",
    "        Dcache = D\n",
    "    \n",
    "    cache = (linear_cache, activation_cache,Dcache)\n",
    "\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardprop(X, parameters):\n",
    "\n",
    "    caches = []\n",
    "    D = []\n",
    "    A = X\n",
    "    L = len(parameters) // 2                \n",
    "    \n",
    "    for l in range(1, L):\n",
    "        A_prev = A \n",
    "        A, cache = linear_activation_forward(A_prev, parameters[\"W\"+str(l)], parameters[\"b\"+str(l)],\"relu\",l)\n",
    "        caches.append(cache)\n",
    "        \n",
    "    AL, cache = linear_activation_forward(A, parameters[\"W\"+str(L)], parameters[\"b\"+str(L)],\"sigmoid\",l)\n",
    "    caches.append(cache)\n",
    "            \n",
    "    return AL, caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(AL, Y,parameters):\n",
    "    \n",
    "    m = Y.shape[1]\n",
    "    #print(AL)\n",
    "    cost = (-1/m)*(np.sum(Y*np.log(AL)+(1-Y)*np.log(1-AL)))\n",
    "    sumW = 0\n",
    "    L = len(parameters) // 2 \n",
    "    for l in range(1, L):\n",
    "        sumW= sumW + np.sum(parameters[\"W\"+str(l)])\n",
    "        \n",
    "    L2_cost= lambd*(sumW)/(2*m)\n",
    "    cost = cost + L2_cost\n",
    "    cost = np.squeeze(cost)     \n",
    "   \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_backward(dZ, linear_cache,keep_prob):\n",
    "    \n",
    "    A_prev, W, b = linear_cache\n",
    "    m = A_prev.shape[1]\n",
    "\n",
    "    dW = (1/m)*np.dot(dZ,A_prev.T)\n",
    "    db = (1/m)*np.sum(dZ,axis=1,keepdims=True)\n",
    "    dA_prev = np.dot(W.T,dZ)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_backward(dA, cache, activation,keep_prob):\n",
    "\n",
    "    linear_cache, activation_cache, dropout_cache = cache\n",
    "    global dA_prev, dW, db\n",
    "    if activation == \"relu\":\n",
    "        dZ = relu_backward(dA,activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache,keep_prob)\n",
    "        \n",
    "    elif activation == \"sigmoid\":\n",
    "        dZ = sigmoid_backward(dA,activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache,keep_prob=1)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop(AL, Y, caches):\n",
    "    grads = {}\n",
    "    L = len(caches) \n",
    "    m = AL.shape[1]\n",
    "    Y = Y.reshape(AL.shape) \n",
    "    \n",
    "    dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
    "    \n",
    "    #print(caches[-2][-1].shape)\n",
    "    #print(L)\n",
    "    \n",
    "    current_cache = caches[-1]\n",
    "    grads[\"dA\" + str(L-1)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL, current_cache,\"sigmoid\",keep_prob=1)\n",
    "    \n",
    "    for l in reversed(range(L-1)):\n",
    "        current_cache = caches[l]\n",
    "        global Dprev_cache\n",
    "        D_prev = caches[l-1][2]\n",
    "        global dA_prev_temp, dW_temp, db_temp\n",
    "        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\" + str(l + 1)], current_cache,\n",
    "                                                                \"relu\",keep_prob)\n",
    "        if l > 0:\n",
    "            dA_prev_temp = np.multiply(dA_prev_temp,D_prev)\n",
    "            dA_prev_temp = dA_prev_temp/keep_prob\n",
    "        grads[\"dA\" + str(l)] = dA_prev_temp\n",
    "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
    "        grads[\"db\" + str(l + 1)] = db_temp\n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_adam(parameters) :\n",
    "\n",
    "    L = len(parameters) // 2 \n",
    "    v = {}\n",
    "    s = {}\n",
    "    \n",
    "    for l in range(L):\n",
    "        v[\"dW\" + str(l+1)] = np.zeros((parameters[\"W\" + str(l+1)].shape[0],parameters[\"W\" + str(l+1)].shape[1]))\n",
    "        v[\"db\" + str(l+1)] = np.zeros((parameters[\"b\" + str(l+1)].shape[0],parameters[\"b\" + str(l+1)].shape[1]))\n",
    "        s[\"dW\" + str(l+1)] = np.zeros((parameters[\"W\" + str(l+1)].shape[0],parameters[\"W\" + str(l+1)].shape[1]))\n",
    "        s[\"db\" + str(l+1)] = np.zeros((parameters[\"b\" + str(l+1)].shape[0],parameters[\"b\" + str(l+1)].shape[1]))\n",
    "   \n",
    "    return v, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, v, s, t,m, learning_rate = 0.01,\n",
    "                                beta1 = 0.9, beta2 = 0.999,  epsilon = 1e-8,):\n",
    "\n",
    "    L = len(parameters) // 2                 \n",
    "    v_corrected = {}                         \n",
    "    s_corrected = {}                        \n",
    "    \n",
    "    # Perform Adam update on all parameters\n",
    "    for l in range(L):\n",
    "        v[\"dW\" + str(l+1)] = beta1*v[\"dW\" + str(l+1)]+(1-beta1)*grads['dW'+str(l+1)]\n",
    "        v[\"db\" + str(l+1)] = beta1*v[\"db\" + str(l+1)]+(1-beta1)*grads['db'+str(l+1)]\n",
    "       \n",
    "        v_corrected[\"dW\" + str(l+1)] = v[\"dW\" + str(l+1)]/(1-pow(beta1,t)) \n",
    "        v_corrected[\"db\" + str(l+1)] = v[\"db\" + str(l+1)]/(1-pow(beta1,t))\n",
    "        \n",
    "        s[\"dW\" + str(l+1)] = beta2*s[\"dW\" + str(l+1)]+(1-beta2)*np.power(grads['dW'+str(l+1)],2)\n",
    "        s[\"db\" + str(l+1)] = beta2*s[\"db\" + str(l+1)]+(1-beta2)*np.power(grads['db'+str(l+1)],2)\n",
    "\n",
    "        s_corrected[\"dW\" + str(l+1)] = s[\"dW\" + str(l+1)]/(1-pow(beta2,t))\n",
    "        s_corrected[\"db\" + str(l+1)] = s[\"db\" + str(l+1)]/(1-pow(beta2,t))\n",
    "\n",
    "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)]-learning_rate*np.divide(v_corrected[\"dW\" + str(l+1)],np.sqrt(s_corrected[\"dW\" + str(l+1)])+epsilon)\n",
    "        parameters[\"W\" + str(l+1)] = parameters[\"W\"+ str(l+1)] +(lambd/m)*parameters[\"W\" + str(l+1)]\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)]-learning_rate*np.divide(v_corrected[\"db\" + str(l+1)],np.sqrt(s_corrected[\"db\" + str(l+1)])+epsilon)\n",
    "\n",
    "    return parameters, v, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, Y, layers_dims, learning_rate0 = 0.003, epocs = 3000,\n",
    "                  beta1 = 0.9, beta2 = 0.999,  epsilon = 1e-8, print_after=1):\n",
    "\n",
    "    costs = []                      \n",
    "    \n",
    "    parameters = initialize_parameters_deep(layers_dims)\n",
    "    v, s = initialize_adam(parameters)\n",
    "    \n",
    "    t = 0\n",
    "    m=X.shape[1]\n",
    "    \n",
    "    for i in range(0, epocs):\n",
    "        AL, caches = forwardprop(X, parameters)\n",
    "        cost = compute_cost(AL, Y,parameters)\n",
    "        grads = backwardprop(AL, Y, caches)\n",
    "        \n",
    "        t = t + 1\n",
    "        learning_rate = learning_rate0/(1+decay_rate*i)\n",
    "        \n",
    "        parameters, v, s = update_parameters_with_adam(parameters, grads, v, s,\n",
    "                                                               t,m, learning_rate, beta1, beta2,  epsilon,)\n",
    "        if i % print_after == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "        if  i % print_after == 0:\n",
    "            costs.append(cost)\n",
    "            \n",
    "    # plot the cost\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per '+str(print_after)+')')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(Y,Yhat,Set):\n",
    "    spos=0\n",
    "    \n",
    "    for i in range(Y.shape[1]): \n",
    "        if Y[0,i]==1 and Yhat[0,i]==1:\n",
    "            spos = spos+1\n",
    "            \n",
    "    p = spos /np.sum(Yhat == 1)\n",
    "    r = spos/ np.sum( Y == 1)\n",
    "    acc = np.mean(Y == Yhat)\n",
    "    f1score = 2*p*r/(p+r)\n",
    "    \n",
    "    #print(Set+\" :       \"+str(p) + \"  \"+str(r)+\"  \"+str(f1score)+\"  \"+str(acc))\n",
    "    error = (1-acc)*100\n",
    "    print(Set+\" :       \"+'%0.3f'%error+\" %\" +'\\t'+str(f1score))\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.717518\n",
      "Cost after iteration 50: 0.675638\n",
      "Cost after iteration 100: 0.626857\n",
      "Cost after iteration 150: 0.567439\n",
      "Cost after iteration 200: 0.513135\n",
      "Cost after iteration 250: 0.461328\n",
      "Cost after iteration 300: 0.413618\n",
      "Cost after iteration 350: 0.370861\n",
      "Cost after iteration 400: 0.333642\n",
      "Cost after iteration 450: 0.302493\n",
      "Cost after iteration 500: 0.277295\n",
      "Cost after iteration 550: 0.258295\n",
      "Cost after iteration 600: 0.245322\n",
      "Cost after iteration 650: 0.236730\n",
      "Cost after iteration 700: 0.230961\n",
      "Cost after iteration 750: 0.226781\n",
      "Cost after iteration 800: 0.224355\n",
      "Cost after iteration 850: 0.223407\n",
      "Cost after iteration 900: 0.222049\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :       9.675 %\t0.9033361847733105\n",
      "Test  :       7.534 %\t0.9246575342465754\n",
      "Seed of initialization : 3\n"
     ]
    }
   ],
   "source": [
    "global dropout_cache\n",
    "global keep_prob\n",
    "global lambd\n",
    "\n",
    "np.random.seed(3)\n",
    "keep_prob=1\n",
    "lambd=0\n",
    "decay_rate=0\n",
    "\n",
    "p = model(train_X, train_Y, layers_dims = [10,64,32,16,8,4,1], epocs =901, \n",
    "                           learning_rate0 = 0.000088,  beta1 = 0.9, beta2 = 0.9,  epsilon = 1e-8, \n",
    "                           print_after = 50)\n",
    "\n",
    "def predict(X,p):\n",
    "    keep_prob=1\n",
    "    AL = forwardprop(X, p)[0]\n",
    "    Y_prediction = AL\n",
    "    for i in range(AL.shape[1]):\n",
    "          Y_prediction[0, i] = 1 if AL[0, i] > 0.5 else 0\n",
    "   \n",
    "    return Y_prediction \n",
    "\n",
    "test_Yhat = predict(test_X,p)\n",
    "train_Yhat = predict(train_X,p)\n",
    "\n",
    "\n",
    "#print(\"    \"+\" :       \"+ \"\\t Precision \" + \"  \"+ \"     \\tRecall\" +\"  \"+\"          F-score \"+\"  \"+\"         Accuracy\")\n",
    "\n",
    "evaluate(train_Y,train_Yhat,\"Train\")\n",
    "evaluate(test_Y,test_Yhat,\"Test \")\n",
    "\n",
    "print(\"Seed of initialization : \"+str(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
